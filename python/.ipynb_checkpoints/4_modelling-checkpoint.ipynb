{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd27bd55",
   "metadata": {},
   "source": [
    "# 4. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899e7a61",
   "metadata": {},
   "source": [
    "## 4.1 Importing useful libraries & functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2713fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# modelling\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# evaluating\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601880ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1a3069",
   "metadata": {},
   "source": [
    "## 4.2 Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a6436f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv('../data/clean_cars_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "082f4945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>cv</th>\n",
       "      <th>km</th>\n",
       "      <th>fuel</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>color</th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>cmixto</th>\n",
       "      <th>class</th>\n",
       "      <th>location</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>326</td>\n",
       "      <td>94000</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>White</td>\n",
       "      <td>6830673</td>\n",
       "      <td>BMW</td>\n",
       "      <td>35900</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Sport</td>\n",
       "      <td>La Rioja</td>\n",
       "      <td>84912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>252</td>\n",
       "      <td>29187</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Manual</td>\n",
       "      <td>White</td>\n",
       "      <td>7477502</td>\n",
       "      <td>Other</td>\n",
       "      <td>65450</td>\n",
       "      <td>6.4</td>\n",
       "      <td>Sport</td>\n",
       "      <td>La Rioja</td>\n",
       "      <td>75240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>40012</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Red</td>\n",
       "      <td>7550291</td>\n",
       "      <td>Renault</td>\n",
       "      <td>20950</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4x4</td>\n",
       "      <td>La Rioja</td>\n",
       "      <td>73336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>224</td>\n",
       "      <td>329000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Black</td>\n",
       "      <td>7593673</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>10900</td>\n",
       "      <td>7.9</td>\n",
       "      <td>4x4</td>\n",
       "      <td>La Rioja</td>\n",
       "      <td>84258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>5450</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Orange</td>\n",
       "      <td>7594227</td>\n",
       "      <td>Renault</td>\n",
       "      <td>23450</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4x4</td>\n",
       "      <td>La Rioja</td>\n",
       "      <td>76140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285217</th>\n",
       "      <td>6</td>\n",
       "      <td>180</td>\n",
       "      <td>51000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Other</td>\n",
       "      <td>7381869</td>\n",
       "      <td>Jaguar</td>\n",
       "      <td>36100</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Valencia</td>\n",
       "      <td>98704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285218</th>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>112399</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Other</td>\n",
       "      <td>7381109</td>\n",
       "      <td>Audi</td>\n",
       "      <td>28700</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Valencia</td>\n",
       "      <td>87032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285219</th>\n",
       "      <td>6</td>\n",
       "      <td>116</td>\n",
       "      <td>62241</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Other</td>\n",
       "      <td>7381085</td>\n",
       "      <td>Audi</td>\n",
       "      <td>18400</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Valencia</td>\n",
       "      <td>80280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285220</th>\n",
       "      <td>7</td>\n",
       "      <td>69</td>\n",
       "      <td>49137</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Other</td>\n",
       "      <td>7381063</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>11155</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Valencia</td>\n",
       "      <td>66130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285221</th>\n",
       "      <td>8</td>\n",
       "      <td>170</td>\n",
       "      <td>69220</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Other</td>\n",
       "      <td>7381033</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>23900</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Valencia</td>\n",
       "      <td>81597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285222 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year   cv      km      fuel    gearbox   color       id     brand  \\\n",
       "0          6  326   94000  Gasoline  Automatic   White  6830673       BMW   \n",
       "1          2  252   29187  Gasoline     Manual   White  7477502     Other   \n",
       "2          4  150   40012  Gasoline     Manual     Red  7550291   Renault   \n",
       "3         14  224  329000    Diesel  Automatic   Black  7593673  Mercedes   \n",
       "4          1   90    5450  Gasoline     Manual  Orange  7594227   Renault   \n",
       "...      ...  ...     ...       ...        ...     ...      ...       ...   \n",
       "285217     6  180   51000    Diesel  Automatic   Other  7381869    Jaguar   \n",
       "285218     5  150  112399    Diesel  Automatic   Other  7381109      Audi   \n",
       "285219     6  116   62241  Gasoline  Automatic   Other  7381085      Audi   \n",
       "285220     7   69   49137  Gasoline     Manual   Other  7381063    Toyota   \n",
       "285221     8  170   69220    Diesel  Automatic   Other  7381033  Mercedes   \n",
       "\n",
       "        price  cmixto     class  location   area  \n",
       "0       35900     6.6     Sport  La Rioja  84912  \n",
       "1       65450     6.4     Sport  La Rioja  75240  \n",
       "2       20950     5.6       4x4  La Rioja  73336  \n",
       "3       10900     7.9       4x4  La Rioja  84258  \n",
       "4       23450     5.3       4x4  La Rioja  76140  \n",
       "...       ...     ...       ...       ...    ...  \n",
       "285217  36100     4.6  Standard  Valencia  98704  \n",
       "285218  28700     4.2  Standard  Valencia  87032  \n",
       "285219  18400     4.6  Standard  Valencia  80280  \n",
       "285220  11155     4.3  Standard  Valencia  66130  \n",
       "285221  23900     5.1  Standard  Valencia  81597  \n",
       "\n",
       "[285222 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e84ea4",
   "metadata": {},
   "source": [
    "## 4.3 Train, Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f297e8",
   "metadata": {},
   "source": [
    "We will divide our data into three datasets. The **training** dataset will teach the model how to operate, the **cross-validation (CV)** dataset will help us optimize the parameters of the models, and finally the **test** dataset will be used to evaluate our final mode and estimate its error and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca4c9933",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cars.drop('price',axis=1)\n",
    "y = cars['price']\n",
    "\n",
    "# Creating train dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "X_train.reset_index(drop=True,inplace=True)\n",
    "y_train.reset_index(drop=True,inplace=True)\n",
    "X_test.reset_index(drop=True,inplace=True)\n",
    "y_test.reset_index(drop=True,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f2c08b",
   "metadata": {},
   "source": [
    "I split the features into numerical and categorical, so I can later normalize and one-hot encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e244be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Training dataset\n",
    "X_num = X_train.select_dtypes(np.number)\n",
    "X_cat = X_train.select_dtypes(object)\n",
    "\n",
    "# 2. Test dataset\n",
    "X_num_test = X_test.select_dtypes(np.number)\n",
    "X_cat_test = X_test.select_dtypes(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e006222",
   "metadata": {},
   "source": [
    "## 4.4 Normalizing numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fdc8c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_scale(numericals, transformer):\n",
    "    normalized = []\n",
    "    for X_numerical in numericals:\n",
    "        X_normalized = transformer.transform(X_numerical)\n",
    "        X_normalized = pd.DataFrame(X_normalized, columns=X_numerical.columns)\n",
    "        normalized.append(X_normalized)\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31ca3f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining normalizer\n",
    "transformer = StandardScaler().fit(X_num)\n",
    "\n",
    "# Applying normalizer\n",
    "X_norm, X_norm_test = std_scale([X_num,X_num_test], transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5090878c",
   "metadata": {},
   "source": [
    "## 4.5 Encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40c43c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(categoricals, encoder):\n",
    "    onehots = []\n",
    "    for X_categorical in categoricals:\n",
    "        encoded = encoder.transform(X_categorical).toarray()\n",
    "        onehot_encode = pd.DataFrame(encoded,columns=encoder.get_feature_names_out(X_categorical.columns))\n",
    "        onehots.append(onehot_encode)\n",
    "    return onehots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "458b80d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating encoder\n",
    "encoder = OneHotEncoder(handle_unknown='error',drop='first').fit(X_cat)\n",
    "\n",
    "# Applying onehot-encode\n",
    "X_oh, X_oh_test = one_hot([X_cat,X_cat_test], encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedff0d9",
   "metadata": {},
   "source": [
    "## 4.6 Concatenating back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed49b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.concat([X_norm, X_oh], axis=1)\n",
    "X_test_scaled = pd.concat([X_norm_test, X_oh_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d467e699",
   "metadata": {},
   "source": [
    "## 4.7 First-glance at models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b8ccbe",
   "metadata": {},
   "source": [
    "#### Linear regression, KNN, Random Forest, XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd583c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LinearRegression()\n",
    "model2 = KNeighborsRegressor()\n",
    "model3 = RandomForestRegressor()\n",
    "model4 = XGBRegressor()\n",
    "\n",
    "model_pipeline = [model1, model2, model3, model4]\n",
    "model_names = ['Linear Regression','KNN','Random Forest', 'XGBoost']\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for model, model_name in zip(model_pipeline, model_names):\n",
    "    mean_score = np.mean(cross_val_score(model, X_train_scaled, y_train, cv=5))\n",
    "    scores[model_name] = mean_score\n",
    "    \n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351e130c",
   "metadata": {},
   "source": [
    "{'Linear Regression': 0.798, 'KNN': 0.932, 'Random Forest': 0.964, 'XGBoost': 0.9414194378541989}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bd96f5",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ee4e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=2, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "scores = []\n",
    "\n",
    "for cv_train, cv_test in kfold.split(X_train_scaled, y_train):\n",
    "    model = Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation = 'relu', name='L4'),\n",
    "        tf.keras.layers.Dense(1, activation = 'relu', name='L5'),\n",
    "\n",
    "    ])\n",
    "    model.compile(loss = MeanSquaredError(), optimizer = tf.keras.optimizers.Adam(learning_rate=0.01))\n",
    "        \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    model.fit(X_train_scaled.loc[cv_train,:], y_train.loc[cv_train], epochs = 5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    y_pred = model.predict(X_train_scaled.loc[cv_test,:])\n",
    "    training_error = r2_score(y_pred,y_train.loc[cv_test])\n",
    "    \n",
    "    print(f'R2 for fold {fold_no}: {training_error:.3f}')\n",
    "    scores.append(training_error)\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "print(f'The CV R2 score is {np.mean(scores):.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c83c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d92afce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=2, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "scores = []\n",
    "\n",
    "for cv_train, cv_test in kfold.split(X_train_scaled, y_train):\n",
    "    model = Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(128, activation = 'relu', name='L1'),\n",
    "        tf.keras.layers.Dense(64, activation = 'relu', name='L4'),\n",
    "        tf.keras.layers.Dense(1, activation = 'relu', name='L5'),\n",
    "\n",
    "    ])\n",
    "    model.compile(loss = MeanSquaredError(), optimizer = tf.keras.optimizers.Adam(learning_rate=0.01))\n",
    "        \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    model.fit(X_train_scaled.loc[cv_train,:], y_train.loc[cv_train], epochs = 5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    y_pred = model.predict(X_train_scaled.loc[cv_test,:])\n",
    "    training_error = r2_score(y_pred,y_train.loc[cv_test])\n",
    "    \n",
    "    print(f'R2 for fold {fold_no}: {training_error:.3f}')\n",
    "    scores.append(training_error)\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "print(f'The CV R2 score is {np.mean(scores):.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a842de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "scores = []\n",
    "\n",
    "for cv_train, cv_test in kfold.split(X_train_scaled, y_train):\n",
    "    model = Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(256, activation = 'relu', name='L1'),\n",
    "        tf.keras.layers.Dense(128, activation = 'relu', name='L2'),\n",
    "        tf.keras.layers.Dense(64, activation = 'relu', name='L4'),\n",
    "        tf.keras.layers.Dense(1, activation = 'relu', name='L5'),\n",
    "\n",
    "    ])\n",
    "    model.compile(loss = MeanSquaredError(), optimizer = tf.keras.optimizers.Adam(learning_rate=0.01))\n",
    "        \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    model.fit(X_train_scaled.loc[cv_train,:], y_train.loc[cv_train], epochs = 5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    y_pred = model.predict(X_train_scaled.loc[cv_test,:])\n",
    "    training_error = r2_score(y_pred,y_train.loc[cv_test])\n",
    "    \n",
    "    print(f'R2 for fold {fold_no}: {training_error:.3f}')\n",
    "    scores.append(training_error)\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "print(f'The CV R2 score is {np.mean(scores):.3f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576a1ba5",
   "metadata": {},
   "source": [
    "## 4.8 Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0f02af",
   "metadata": {},
   "source": [
    "## 4.7 Training models & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f40de6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lmbd = 0\n",
    "model1 = LinearRegression()\n",
    "model2 = KNeighborsRegressor()\n",
    "model3 = DecisionTreeRegressor()\n",
    "model4 = RandomForestRegressor()\n",
    "model5 = XGBRegressor()\n",
    "model6 = Sequential(\n",
    "[\n",
    "    tf.keras.layers.Dense(2048, activation = 'relu', name='L1', kernel_regularizer=L2(lmbd)),\n",
    "    tf.keras.layers.Dense(2048, activation = 'relu', name='L2', kernel_regularizer=L2(lmbd)),\n",
    "    tf.keras.layers.Dense(1, activation = 'relu', name='L7'),\n",
    "\n",
    "]\n",
    ")\n",
    "model6.compile(loss = MeanSquaredError(),optimizer = tf.keras.optimizers.Adam(learning_rate=0.01))\n",
    "model_pipeline = [model1,  model4, model6, model5,]\n",
    "model_names = ['Linear Regression', 'RandomForest', 'NeuralNetwork' ,'XGBoost']\n",
    "\n",
    "scores = {}\n",
    "for model, model_name in zip(model_pipeline, model_names):\n",
    "    print('Working with model '+model_name)\n",
    "    \n",
    "    # Fitting the model\n",
    "    if model_name == 'NeuralNetwork':\n",
    "        model.fit(X_train_scaled, y_train, epochs = 30)\n",
    "    else:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_train_scaled)\n",
    "    training_error = r2_score(y_pred,y_train)\n",
    "    \n",
    "    scores[model_name] = [round(training_error,3)]\n",
    "    \n",
    "print(scores)\n",
    "# We can use the result to choose the best performing model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c68696",
   "metadata": {},
   "source": [
    "## 4.7 Hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3153d0b",
   "metadata": {},
   "source": [
    "### 4.7.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9731443",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "max_depth_choices= [5,10,None]\n",
    "min_samples_split_choices = [2,12]\n",
    "min_samples_leaf_choices = [1,6]\n",
    "\n",
    "random_grid = {'max_depth': max_depth_choices,\n",
    "'min_samples_split': min_samples_split_choices,\n",
    "'min_samples_leaf': min_samples_leaf_choices}\n",
    "\n",
    "# Instantiate the grid search model object\n",
    "# estimator -> model to optimize\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = model, param_distributions = random_grid, n_iter=12, cv = 5, n_jobs = 8)\n",
    "\n",
    "random_search.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d643c740",
   "metadata": {},
   "source": [
    "best_forest_param = {'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}, which are the default ones\n",
    "best_forest_score = 0.962"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af794502",
   "metadata": {},
   "source": [
    "### 4.7.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9134fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "        'max_depth': [3, 7, 11, 13, 15, 17, None],\n",
    "        'min_child_weight': np.arange(0.0001, 0.5, 0.05),\n",
    "        'learning_rate': np.arange(0.0005,0.3,0.025),\n",
    "        'subsample': np.arange(0.01,1.0,0.005),\n",
    "        'colsample_bylevel': np.round(np.arange(0.1,1.0,0.05)),\n",
    "        'colsample_bytree': np.arange(0.1,1.0,0.05),\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model object\n",
    "# estimator -> model to optimize\n",
    "model = XGBRegressor()\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = model, param_distributions = param_grid, n_iter=100, cv = 5, n_jobs = 8)\n",
    "\n",
    "random_search.fit(X_train_scaled,y_train)\n",
    "#random_search.best_params_\n",
    "#random_search.best_score_"
   ]
  },
  {
   "cell_type": "raw",
   "id": "08ca3874",
   "metadata": {},
   "source": [
    "best_xgboost_params = {'subsample': 0.935,'min_child_weight': 0.2001,'max_depth': 17,\n",
    "        'learning_rate': 0.0755,'colsample_bytree': 0.7,'colsample_bylevel': 1.0}\n",
    "best_xgboost_score = 0.967"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc8dc82",
   "metadata": {},
   "source": [
    "# 4.8 Model training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d22b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(**{'subsample': 0.935,'min_child_weight': 0.2001,'max_depth': 17,\n",
    "        'learning_rate': 0.0755,'colsample_bytree': 0.7,'colsample_bylevel': 1.0})\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "test_error = r2_score(y_pred,y_test)\n",
    "test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03be4a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "error =int((abs(np.round(y_pred,0).flatten()-y_test)/np.round(y_pred,0).flatten()*100).astype(int).values.mean())\n",
    "std = int((abs(np.round(y_pred,0).flatten()-y_test)/np.round(y_pred,0).flatten()*100).astype(int).values.std())\n",
    "print('The error for 99% of the test samples is equal or lower than',abs(error)+abs(std)*3,'% of the price.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c45ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <!> I could try to use log or sqrt of some qualities like cv and more that seem to over emphasize \n",
    "# the price of high values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aff500",
   "metadata": {},
   "source": [
    "Computing R2 for a more realistic dataset. ID duplicates were not removed because many cars were being sold in different regions at the same time. Removing them would remove that geographical information. I decided to to keep some duplicated listings them, but here I am now removing all duplicates in the test set to compute the real R2 (it goes down from 0.95 to 0.94)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72377764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9963453791474945"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor(**{'subsample': 0.935,'min_child_weight': 0.2001,'max_depth': 17,\n",
    "        'learning_rate': 0.0755,'colsample_bytree': 0.7,'colsample_bylevel': 1.0})\n",
    "model.fit(X_train_scaled.drop(['id'],axis=1), y_train)\n",
    "y_pred = model.predict(X_train_scaled.drop(['id'],axis=1))\n",
    "train_error = r2_score(y_pred,y_train)\n",
    "train_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02421fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X_test_scaled.copy()\n",
    "test = pd.concat([test,y_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfc04f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop_duplicates(subset=['id']).drop(['id'],axis=1)\n",
    "ytest = test['price'].copy()\n",
    "xtest = test.drop(['price'],axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c97176b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9534098477720633"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(xtest)\n",
    "test_error = r2_score(y_pred,ytest)\n",
    "test_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a123a473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error for 90% of the test samples is equal or lower than 30 %.\n"
     ]
    }
   ],
   "source": [
    "error =int((abs(np.round(y_pred,0).flatten()-ytest)/ytest*100).astype(int).values.mean())\n",
    "std = int((abs(np.round(y_pred,0).flatten()-ytest)/ytest*100).astype(int).values.std())\n",
    "print('The error for 90% of the test samples is equal or lower than',abs(error)+abs(std)*2,'%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27b495c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pickle.dump(encoder, open('../machine-learning/encoder.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa07fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(transformer, open('../machine-learning/normalizer.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac11d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(model, open('../machine-learning/xgboost.p','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
